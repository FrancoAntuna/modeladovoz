{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "import logging\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import traceback\n",
    "from ipywidgets import Button\n",
    "import subprocess\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import IPython.display as ipd\n",
    "from random import shuffle\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Button(button_style='success', description='✔ Success', style=ButtonStyle())\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "project_folder = os.path.join(current_directory, \"project-main\")\n",
    "dataset_folder = os.path.join(current_directory, \"dataset\")\n",
    "logs_folder = os.path.join(project_folder, \"logs\")\n",
    "#@title 1.Preprocess Data\n",
    "os.chdir(project_folder)\n",
    "model_name = str(input(\"Inserte el nonmbre del modelo: \")) #@param {type:\"string\"}\n",
    "#@markdown <small> Enter the path to your dataset folder (a folder with audios of the vocals you will train on), or if you want just upload the audios using the File Manager into the 'dataset' folder.\n",
    "while len(os.listdir(dataset_folder)) < 1:\n",
    "    print(\"Your dataset folder is empty.\")\n",
    "    sys.exit()\n",
    "model_logs_folder = os.path.join(logs_folder, model_name)\n",
    "os.makedirs(model_logs_folder, exist_ok=True)\n",
    "with open(os.path.join(model_logs_folder, \"preprocess.log\"), 'w') as f:\n",
    "    f.write(\"Starting...\")\n",
    "script_path = os.path.join(project_folder, \"infer/modules/train/preprocess.py\")\n",
    "comando = [\n",
    "    \"python\",\n",
    "    script_path,\n",
    "    dataset_folder,\n",
    "    \"40000\",\n",
    "    \"2\",\n",
    "    model_logs_folder,\n",
    "    \"False\",\n",
    "    \"3.0\"\n",
    "]\n",
    "subprocess.run(comando)\n",
    "with open(os.path.join(model_logs_folder, \"preprocess.log\"), 'r') as f:\n",
    "    if 'end preprocess' in f.read():\n",
    "        clear_output()\n",
    "        print(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
    "    else:\n",
    "        print(\"Error preprocessing data... Make sure your dataset folder is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(current_directory)\n",
    "print(dataset_folder)\n",
    "print(logs_folder)\n",
    "print(project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error preprocessing data... Make sure your data was preprocessed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs(logs_folder, exist_ok=True)\n",
    "f0method = \"rmvpe_gpu\" # @param [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n",
    "os.chdir(project_folder)\n",
    "with open(os.path.join(logs_folder, \"extract_f0_feature.log\"), 'w') as f:\n",
    "    f.write(\"Starting...\")\n",
    "extract_f0_script = os.path.join(project_folder, \"infer/modules/train/extract/extract_f0_rmvpe.py\")\n",
    "extract_feature_script = os.path.join(project_folder, \"infer/modules/train/extract_feature_print.py\")\n",
    "comando_1 = [\n",
    "    \"python\",\n",
    "    extract_f0_script,\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    logs_folder,\n",
    "    \"True\"\n",
    "]\n",
    "comando_2 = [\n",
    "    \"python\",\n",
    "    extract_feature_script,\n",
    "    \"cuda:0\",\n",
    "    \"1\",\n",
    "    \"0\",\n",
    "    \"0\",\n",
    "    logs_folder,\n",
    "    \"v2\"\n",
    "]\n",
    "subprocess.run(comando_1)\n",
    "subprocess.run(comando_2)\n",
    "\n",
    "log_file = os.path.join(logs_folder, \"extract_f0_feature.log\")\n",
    "\n",
    "# Realizar el procesamiento necesario aquí...\n",
    "\n",
    "\n",
    "with open(os.path.join(logs_folder, \"extract_f0_feature.log\"), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    if any('all-feature-done' in line for line in lines):\n",
    "        clear_output()\n",
    "        print(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
    "    else:\n",
    "        print(\"Error preprocessing data... Make sure your data was preprocessed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_index(exp_dir1, version19, n_cpu, project_folder):\n",
    "    exp_dir = os.path.join(project_folder, \"logs\", exp_dir1)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    feature_dir = os.path.join(exp_dir, \"3_feature256\" if version19 == \"v1\" else \"3_feature768\")\n",
    "    os.makedirs(feature_dir)\n",
    "    if not os.path.exists(feature_dir):\n",
    "        return \"¡Por favor, realiza la extracción de características primero!\"\n",
    "    listdir_res = list(os.listdir(feature_dir))\n",
    "    if len(listdir_res) == 0:\n",
    "        return \"¡Por favor, realice la extracción de características primero!\"\n",
    "    infos = []\n",
    "    npys = []\n",
    "    for name in sorted(listdir_res):\n",
    "        phone = np.load(os.path.join(feature_dir, name))\n",
    "        npys.append(phone)\n",
    "    big_npy = np.concatenate(npys, 0)\n",
    "    big_npy_idx = np.arange(big_npy.shape[0])\n",
    "    np.random.shuffle(big_npy_idx)\n",
    "    big_npy = big_npy[big_npy_idx]\n",
    "    if big_npy.shape[0] > 2e5:\n",
    "        infos.append(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
    "        yield \"\\n\".join(infos)\n",
    "        try:\n",
    "            big_npy = (\n",
    "                MiniBatchKMeans(\n",
    "                    n_clusters=10000,\n",
    "                    verbose=True,\n",
    "                    batch_size=256 * n_cpu,\n",
    "                    compute_labels=False,\n",
    "                    init=\"random\",\n",
    "                )\n",
    "                .fit(big_npy)\n",
    "                .cluster_centers_\n",
    "            )\n",
    "        except:\n",
    "            info = traceback.format_exc()\n",
    "            logger.info(info)\n",
    "            infos.append(info)\n",
    "            yield \"\\n\".join(infos)\n",
    "\n",
    "    np.save(os.path.join(exp_dir, \"total_fea.npy\"), big_npy)\n",
    "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
    "    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
    "    yield \"\\n\".join(infos)\n",
    "    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
    "    infos.append(\"training\")\n",
    "    yield \"\\n\".join(infos)\n",
    "    index_ivf = faiss.extract_index_ivf(index)  #\n",
    "    index_ivf.nprobe = 1\n",
    "    index.train(big_npy)\n",
    "    faiss.write_index(\n",
    "        index,\n",
    "        os.path.join(\n",
    "            exp_dir,\n",
    "            \"trained_IVF%s_Flat_nprobe_%s_%s_%s.index\" % (n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    infos.append(\"adding\")\n",
    "    yield \"\\n\".join(infos)\n",
    "    batch_size_add = 8192\n",
    "    for i in range(0, big_npy.shape[0], batch_size_add):\n",
    "        index.add(big_npy[i : i + batch_size_add])\n",
    "    faiss.write_index(\n",
    "        index,\n",
    "        os.path.join(\n",
    "            exp_dir,\n",
    "            \"added_IVF%s_Flat_nprobe_%s_%s_%s.index\" % (n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
    "        ),\n",
    "    )\n",
    "    infos.append(\n",
    "        \"Índice construido con éxito, added_IVF%s_Flat_nprobe_%s_%s_%s.index\" % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
    "    )\n",
    "\n",
    "training_log = train_index(model_name, 'v2', 6, project_folder)\n",
    "\n",
    "for line in training_log:\n",
    "    print(line)\n",
    "    if 'adding' in line:\n",
    "        clear_output()\n",
    "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_frequency = 40\n",
    "epochs = 1000\n",
    "cache = True\n",
    "now_dir = project_folder\n",
    "\n",
    "def click_train(\n",
    "    exp_dir1,\n",
    "    sr2,\n",
    "    if_f0_3,\n",
    "    spk_id5,\n",
    "    save_epoch10,\n",
    "    total_epoch11,\n",
    "    batch_size12,\n",
    "    if_save_latest13,\n",
    "    pretrained_G14,\n",
    "    pretrained_D15,\n",
    "    gpus16,\n",
    "    if_cache_gpu17,\n",
    "    if_save_every_weights18,\n",
    "    version19,\n",
    "    now_dir,  # Añade esta variable para obtener la ruta actual\n",
    "):\n",
    "    exp_dir = os.path.join(now_dir, \"logs\", exp_dir1)  # Construye la ruta completa hasta el directorio de experimentos\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    gt_wavs_dir = os.path.join(exp_dir, \"0_gt_wavs\")  # Usa os.path.join para construir rutas de manera segura\n",
    "    feature_dir = (\n",
    "        os.path.join(exp_dir, \"3_feature256\")\n",
    "        if version19 == \"v1\"\n",
    "        else os.path.join(exp_dir, \"3_feature768\")\n",
    "    )\n",
    "    if if_f0_3:\n",
    "        f0_dir = os.path.join(exp_dir, \"2a_f0\")\n",
    "        f0nsf_dir = os.path.join(exp_dir, \"2b-f0nsf\")\n",
    "        names = (\n",
    "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
    "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
    "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
    "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
    "        )\n",
    "    else:\n",
    "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
    "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
    "        )\n",
    "    opt = []\n",
    "    for name in names:\n",
    "        if if_f0_3:\n",
    "            opt.append(\n",
    "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
    "                % (\n",
    "                    os.path.join(gt_wavs_dir, name),\n",
    "                    os.path.join(feature_dir, name),\n",
    "                    os.path.join(f0_dir, name),\n",
    "                    os.path.join(f0nsf_dir, name),\n",
    "                    spk_id5,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            opt.append(\n",
    "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
    "                % (\n",
    "                    os.path.join(gt_wavs_dir, name),\n",
    "                    os.path.join(feature_dir, name),\n",
    "                    spk_id5,\n",
    "                )\n",
    "            )\n",
    "    fea_dim = 256 if version19 == \"v1\" else 768\n",
    "    if if_f0_3:\n",
    "        for _ in range(2):\n",
    "            opt.append(\n",
    "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
    "                % (current_directory, sr2, current_directory, fea_dim, current_directory, current_directory, spk_id5)\n",
    "            )\n",
    "    else:\n",
    "        for _ in range(2):\n",
    "            opt.append(\n",
    "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
    "                % (current_directory, sr2, current_directory, fea_dim, spk_id5)\n",
    "            )\n",
    "    shuffle(opt)\n",
    "    with open(os.path.join(exp_dir, \"filelist.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(opt))\n",
    "\n",
    "    # Replace logger.debug, logger.info with print statements\n",
    "    print(\"Write filelist done\")\n",
    "    print(\"Use gpus:\", str(gpus16))\n",
    "    if pretrained_G14 == \"\":\n",
    "        print(\"No pretrained Generator\")\n",
    "    if pretrained_D15 == \"\":\n",
    "        print(\"No pretrained Discriminator\")\n",
    "    if version19 == \"v1\" or sr2 == \"40k\":\n",
    "        config_path = os.path.join(project_main_folder, \"configs/v1/%s.json\" % sr2)\n",
    "    else:\n",
    "        config_path = os.path.join(project_main_folder, \"configs/v2/%s.json\" % sr2)\n",
    "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
    "    if not os.path.exists(config_save_path):\n",
    "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            with open(config_path, \"r\") as config_file:\n",
    "                config_data = json.load(config_file)\n",
    "                json.dump(\n",
    "                    config_data,\n",
    "                    f,\n",
    "                    ensure_ascii=False,\n",
    "                    indent=4,\n",
    "                    sort_keys=True,\n",
    "                )\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    cmd = (\n",
    "        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n",
    "        % (\n",
    "            exp_dir1,\n",
    "            sr2,\n",
    "            1 if if_f0_3 else 0,\n",
    "            batch_size12,\n",
    "            gpus16,\n",
    "            total_epoch11,\n",
    "            save_epoch10,\n",
    "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
    "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
    "            1 if if_save_latest13 == True else 0,\n",
    "            1 if if_cache_gpu17 == True else 0,\n",
    "            1 if if_save_every_weights18 == True else 0,\n",
    "            version19,\n",
    "        )\n",
    "    )\n",
    "    # Use PIPE to capture the output and error streams\n",
    "    p = Popen(cmd, shell=True, cwd=project_main_folder, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
    "\n",
    "    # Print the command's output as it runs\n",
    "    for line in p.stdout:\n",
    "        print(line.strip())\n",
    "\n",
    "    # Wait for the process to finish\n",
    "    p.wait()\n",
    "    return \"Entrenamiento finalizado. Puede revisar el registro de entrenamiento en la consola o en la carpeta experimental como train.log.\"\n",
    "\n",
    "\n",
    "training_log = click_train(\n",
    "    model_name,\n",
    "    '40k',\n",
    "    True,\n",
    "    0,\n",
    "    save_frequency,\n",
    "    epochs,\n",
    "    12,\n",
    "    True,\n",
    "    os.path.join(project_folder, \"assets/pretrained_v2/f0G40k.pth\"),\n",
    "    os.path.join(project_folder, \"assets/pretrained_v2/f0D40k.pth\"),\n",
    "    0,\n",
    "    cache,\n",
    "    True,\n",
    "    'v2',\n",
    "    now_dir\n",
    ")\n",
    "print(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Inference\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "project_folder = os.path.join(current_directory, \"Proyecto/project-main\")\n",
    "dataset_folder = os.path.join(current_directory, \"Proyecto/dataset\")\n",
    "logs_folder = os.path.join(project_folder, \"logs\")\n",
    "transpose = 0  # Modificar según tus necesidades\n",
    "input_path = str(os.path.join(current_directory, \"modelizar\", \"Voces\", \"Apocalipsis.mp3\"))\n",
    "print(input_path)\n",
    "index_path = str(os.path.join(current_directory, \"Proyecto\", \"project-main\", \"logs\", \"DV4\", \"trained_IVF1353_Flat_nprobe_1_DV4_v2.index\"))\n",
    "f0_method = \"rmvpe\"  # Opción de método para frecuencia fundamental\n",
    "opt_path = str(os.path.join(current_directory, \"Proyecto\", \"dataset\", \"cli_output.wav\"))\n",
    "index_rate = 0.66  # Tasa de índice\n",
    "volume_normalization = 0  # Normalización de volumen\n",
    "consonant_protection = 0  # Protección de consonantes\n",
    "infer_cli_path = os.path.join(current_directory, \"Proyecto\", \"project-main\", \"tools\", \"infer_cli.py\")\n",
    "model_path = \"DV4_e1000_s32000.pth\"\n",
    "\n",
    "print(infer_cli_path)\n",
    "print(opt_path)\n",
    "print(\"python\",\n",
    "    infer_cli_path,\n",
    "    \"--f0up_key\", str(transpose),\n",
    "    \"--input_path\", '\"' + input_path + '\"',\n",
    "    \"--index_path\", '\"' + index_path + '\"',\n",
    "    \"--f0method\", f0_method,\n",
    "    \"--opt_path\", '\"' + opt_path + '\"',\n",
    "    \"--model_name\", model_path,\n",
    "    \"--index_rate\", str(index_rate),\n",
    "    \"--device\", \"cuda:0\",\n",
    "    \"--is_half\", \"True\",\n",
    "    \"--filter_radius\", \"3\",\n",
    "    \"--resample_sr\", \"0\",\n",
    "    \"--rms_mix_rate\", str(volume_normalization),\n",
    "    \"--protect\", str(consonant_protection))\n",
    "\n",
    "comando_ps = [\n",
    "    \"python\",\n",
    "    infer_cli_path,\n",
    "    \"--f0up_key\", str(transpose),\n",
    "    \"--input_path\", input_path,\n",
    "    \"--index_path\", index_path,\n",
    "    \"--f0method\", f0_method,\n",
    "    \"--opt_path\", opt_path,\n",
    "    \"--model_name\", model_path,\n",
    "    \"--index_rate\", str(index_rate),\n",
    "    \"--device\", \"cuda:0\",\n",
    "    \"--is_half\", \"True\",\n",
    "    \"--filter_radius\", \"3\",\n",
    "    \"--resample_sr\", \"0\",\n",
    "    \"--rms_mix_rate\", str(volume_normalization),\n",
    "    \"--protect\", str(consonant_protection)\n",
    "]\n",
    "\n",
    "subprocess.run([\"powershell\", \"-Command\", \" \".join(comando_ps)], capture_output=True, text=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
